{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef38f16f-4e9e-44c1-bdd3-d1abccc78549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.special import erf\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "\n",
    "def EFP(time: np.int32 | npt.NDArray[np.int32], amplitude: np.float64, mu: np.float64, sigma: np.float64, tau: np.float64) -> np.float64 | npt.NDArray[np.float64]:\n",
    "    Aprime = amplitude * sigma / (tau * np.sqrt(2 / np.pi))\n",
    "    y1 = -(time - mu) / tau + sigma**2 / (2 * tau**2)\n",
    "    y2 = (time - mu) / (np.sqrt(2) * sigma) - sigma / (np.sqrt(2) * tau)\n",
    "    return Aprime * np.exp(y1) * (1 + erf(y2))\n",
    "\n",
    "def plot_flare(identifier: str):\n",
    "    dirname = ''\n",
    "    datafile = f'{dirname}flares/{identifier}.csv'\n",
    "    df = pd.read_csv(datafile)\n",
    "    summaryfile = f'{dirname}allflares_preprocessed.csv'\n",
    "    allcsv = pd.read_csv(summaryfile)\n",
    "    row = allcsv[allcsv['identifier'] == identifier].iloc[0]\n",
    "\n",
    "    fig, axs = plt.subplots(2, figsize=(9.6, 9.6), gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "    axs[0].set_title(f'{identifier}')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.subplots_adjust(hspace=.0)\n",
    "    linestyle = {\"elinewidth\":1, \"capsize\":0, \"ecolor\":\"grey\"}\n",
    "    plt.setp(axs[0].get_xticklabels(), visible=False)\n",
    "\n",
    "    xt = df['Time']\n",
    "    yt = df['Counts']\n",
    "    yerr = df['Error']\n",
    "\n",
    "    axs[0].errorbar(xt, yt, yerr=yerr, fmt='D', ms=3, c='blue', **linestyle)\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.tick_params(which='major', width=1)\n",
    "        ax.tick_params(which='major', length=4)\n",
    "        ax.margins(x=0)\n",
    "    axs[0].set_ylabel('Flux (nW/m$^2$)')\n",
    "    axs[1].set_ylabel('Residual ((o-f)/$\\\\sigma$)')\n",
    "    axs[1].set_ylim(bottom=-4,top=4)\n",
    "\n",
    "    range = (np.max(yt) - np.min(yt))/10\n",
    "    axs[0].scatter(row['start_time'], \\\n",
    "        row['start_count'], c='k', s=30, zorder=15)\n",
    "    axs[0].vlines(x=row['start_time'], \\\n",
    "        ymin=row['start_count'] - range, \\\n",
    "        ymax=row['end_count'] + range, color='k', linestyle='dotted', linewidth=2)\n",
    "    axs[0].scatter(row['end_time'], \\\n",
    "        row['end_count'], c='k', s=30, zorder=15)\n",
    "    axs[0].vlines(x=row['end_time'], \\\n",
    "        ymin=row['end_count'] - range, \\\n",
    "        ymax=row['end_count'] + range, color='k', linestyle='dotted', linewidth=2)\n",
    "\n",
    "    yfit = EFP(xt, row['amplitude'], row['mu'], row['sigma'], row['tau'])\n",
    "    axs[0].plot(xt, yfit, c='r', zorder=10, lw=3)\n",
    "    axs[0].tick_params(axis='x', direction='in')\n",
    "    axs[1].errorbar(xt, (yt-yfit)/np.std(yt-yfit), yerr=yerr/np.std(yt-yfit), fmt='D', ms=3, c='blue', **linestyle)\n",
    "    axs[1].axhline(np.mean((yt-yfit)/np.std(yt-yfit)), linestyle='--', lw=1, c='navy')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fbf7792c-5cfa-48d2-bc15-b431fb2ddd42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date identifier  start_time  start_count  peak_time  peak_count  \\\n",
      "0     20221104  20221104q     82785.0         9.56    82965.0      101.03   \n",
      "1     20221104  20221104a      8135.0         4.08     8455.0       42.79   \n",
      "2     20221104  20221104p     80175.0        49.67    80575.0      507.60   \n",
      "3     20221104  20221104o     72505.0        10.25    73475.0      103.02   \n",
      "4     20221104  20221104n     71875.0         0.00    74915.0       20.66   \n",
      "...        ...        ...         ...          ...        ...         ...   \n",
      "8039  20190921  20190921a     15395.0         0.32    15585.0        3.26   \n",
      "8040  20190917  20190917b     70935.0         0.90    71015.0        7.00   \n",
      "8041  20190917  20190917a     60615.0         0.25    60895.0        2.45   \n",
      "8042  20190915  20190915a     65555.0         0.14    66025.0        1.37   \n",
      "8043  20190914  20190914a     74075.0         0.19    74215.0        2.05   \n",
      "\n",
      "      end_time  end_count  scpeaks0-05  multi_flare_region_flag  ...  \\\n",
      "0      83655.0      13.85            1                    False  ...   \n",
      "1       8785.0       4.13            6                    False  ...   \n",
      "2      82615.0     129.80            1                    False  ...   \n",
      "3      75295.0      70.03            6                     True  ...   \n",
      "4      75295.0      11.98            6                     True  ...   \n",
      "...        ...        ...          ...                      ...  ...   \n",
      "8039   15975.0       0.33           20                    False  ...   \n",
      "8040   71215.0       0.69           15                    False  ...   \n",
      "8041   61415.0       0.25           12                    False  ...   \n",
      "8042   66505.0       0.14           18                    False  ...   \n",
      "8043   74905.0       0.21           18                    False  ...   \n",
      "\n",
      "      amplitude        mu   sigma      tau  redchisq  rsquared     snr  \\\n",
      "0        311.52  82874.65   61.21   329.99   106.529     0.883  134.37   \n",
      "1         43.39   8435.23  147.99    25.00   199.630     0.571   60.91   \n",
      "2       2114.62  80434.14  175.50  1230.74   761.981     0.952  594.35   \n",
      "3        513.42  73015.00  364.05  3518.37   189.323     0.822  292.76   \n",
      "4         20.89  74863.92  357.32    54.72   189.323     0.248   19.31   \n",
      "...         ...       ...     ...      ...       ...       ...     ...   \n",
      "8039       5.65  15505.91   70.91   151.24     0.186     0.785   49.34   \n",
      "8040      13.86  70976.08   29.52    79.72     0.295     0.841   38.79   \n",
      "8041       3.76  60795.40  113.09   185.74     0.172     0.792   58.77   \n",
      "8042       1.39  65982.45  216.56    46.39     0.422     0.329   36.05   \n",
      "8043       7.11  74142.01   46.06   290.44     0.198     0.576   43.37   \n",
      "\n",
      "       fluence  flare_type  duration  \n",
      "0      4331.99           B     870.0  \n",
      "1      1789.12           A     650.0  \n",
      "2     19913.89           B    2440.0  \n",
      "3      7879.08           B    2790.0  \n",
      "4       532.73           F    3420.0  \n",
      "...        ...         ...       ...  \n",
      "8039     95.15           B     580.0  \n",
      "8040     94.35           B     280.0  \n",
      "8041     99.95           B     800.0  \n",
      "8042     71.73           F     950.0  \n",
      "8043     77.28           B     830.0  \n",
      "\n",
      "[8044 rows x 23 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8044/8044 [00:04<00:00, 2002.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.signal import welch\n",
    "from tqdm import tqdm\n",
    "\n",
    "class_info = pd.read_csv('allflares_preprocessed.csv')\n",
    "\n",
    "print(class_info)\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "ids = []\n",
    "peak_count = []\n",
    "\n",
    "tot_flares = 0\n",
    "\n",
    "for i, iden in enumerate(tqdm(np.array(class_info['identifier']))):\n",
    "    if class_info['flare_type'][i] != 'A' and class_info['flare_type'][i] != 'B':\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        tod = pd.read_csv('flares/' + iden + '.csv')\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "\n",
    "    if np.max(np.diff(tod['Time'])) > 10 or np.max(np.diff(tod['Time'])) < 10:\n",
    "        continue\n",
    "\n",
    "    tot_flares += 1\n",
    "    data.append(list(tod['Counts']))\n",
    "    peak_count.append(class_info['peak_count'][i])\n",
    "    \n",
    "    if class_info['flare_type'][i] == 'A':\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)\n",
    "\n",
    "    ids.append(class_info['identifier'][i])\n",
    "\n",
    "    \"\"\"\n",
    "    print(np.array(tod['Counts']))\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    plt.scatter(np.array(tod['Time']) - np.array(tod['Time'])[0], np.array(tod['Counts']))\n",
    "    plt.errorbar(np.array(tod['Time']) - np.array(tod['Time'])[0], np.array(tod['Counts']), np.array(tod['Error']), ls='')\n",
    "\n",
    "    plt.title(class_info['identifier'][i] + ': ' + class_info['flare_type'][i], fontsize=24)\n",
    "\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(tot_flares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1ff2bf4b-58c8-44e0-9ce5-6e7fc7d78e23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.6400759  13.31584982 25.55306329 ...  0.          0.\n",
      "  0.        ]\n",
      "(3704, 2089)\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "data = pad_sequences(data, padding='post', dtype=float)\n",
    "\n",
    "print(data[0])\n",
    "print(data.shape)\n",
    "print(type(data[0, 0]))\n",
    "\n",
    "#print(labels)\n",
    "\n",
    "#for d in data:\n",
    "#    plt.scatter(range(len(d)), d)\n",
    "#    \n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78737b1f-4de4-4f37-8270-fe20694ddf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrchu/anaconda3/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "    \n",
    "# First convolutional layer\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(len(data[0]), 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Second convolutional layer\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Third convolutional layer\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Flatten the output\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3939740b-be3c-46c6-8012-483ee3380c4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.7305 - loss: 4.3398 - val_accuracy: 0.8273 - val_loss: 0.4977\n",
      "Epoch 2/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8030 - loss: 0.5291 - val_accuracy: 0.8273 - val_loss: 0.4704\n",
      "Epoch 3/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7963 - loss: 0.5082 - val_accuracy: 0.8273 - val_loss: 0.4543\n",
      "Epoch 4/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7897 - loss: 0.4975 - val_accuracy: 0.8273 - val_loss: 0.4625\n",
      "Epoch 5/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8024 - loss: 0.4742 - val_accuracy: 0.8273 - val_loss: 0.4854\n",
      "Epoch 6/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8114 - loss: 0.4545 - val_accuracy: 0.8259 - val_loss: 0.4540\n",
      "Epoch 7/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8155 - loss: 0.4569 - val_accuracy: 0.8273 - val_loss: 0.4483\n",
      "Epoch 8/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8038 - loss: 0.4506 - val_accuracy: 0.8300 - val_loss: 0.4526\n",
      "Epoch 9/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8054 - loss: 0.4850 - val_accuracy: 0.8367 - val_loss: 0.4828\n",
      "Epoch 10/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8255 - loss: 0.4254 - val_accuracy: 0.8300 - val_loss: 0.4422\n",
      "Epoch 11/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8266 - loss: 0.4121 - val_accuracy: 0.8286 - val_loss: 0.4432\n",
      "Epoch 12/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8390 - loss: 0.4046 - val_accuracy: 0.8232 - val_loss: 0.4689\n",
      "Epoch 13/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8125 - loss: 0.4244 - val_accuracy: 0.8259 - val_loss: 0.4556\n",
      "Epoch 14/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8292 - loss: 0.5001 - val_accuracy: 0.8246 - val_loss: 0.5122\n",
      "Epoch 15/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8488 - loss: 0.3576 - val_accuracy: 0.8259 - val_loss: 0.4711\n",
      "Epoch 16/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8620 - loss: 0.3674 - val_accuracy: 0.8273 - val_loss: 0.4524\n",
      "Epoch 17/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8757 - loss: 0.2954 - val_accuracy: 0.8259 - val_loss: 0.4949\n",
      "Epoch 18/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8719 - loss: 0.3246 - val_accuracy: 0.8313 - val_loss: 0.4544\n",
      "Epoch 19/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8704 - loss: 0.2943 - val_accuracy: 0.8259 - val_loss: 0.5358\n",
      "Epoch 20/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8912 - loss: 0.2530 - val_accuracy: 0.8232 - val_loss: 0.5652\n",
      "Epoch 21/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9091 - loss: 0.2294 - val_accuracy: 0.8327 - val_loss: 0.5408\n",
      "Epoch 22/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9063 - loss: 0.2204 - val_accuracy: 0.8246 - val_loss: 0.6153\n",
      "Epoch 23/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9305 - loss: 0.1735 - val_accuracy: 0.8286 - val_loss: 0.5732\n",
      "Epoch 24/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8930 - loss: 0.4986 - val_accuracy: 0.8192 - val_loss: 0.6796\n",
      "Epoch 25/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8447 - loss: 0.5253 - val_accuracy: 0.8273 - val_loss: 0.5459\n",
      "Epoch 26/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8868 - loss: 0.2755 - val_accuracy: 0.8138 - val_loss: 0.5552\n",
      "Epoch 27/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9127 - loss: 0.2201 - val_accuracy: 0.8259 - val_loss: 0.5917\n",
      "Epoch 28/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9316 - loss: 0.1785 - val_accuracy: 0.8219 - val_loss: 0.6872\n",
      "Epoch 29/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9289 - loss: 0.2062 - val_accuracy: 0.8138 - val_loss: 0.6577\n",
      "Epoch 30/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9426 - loss: 0.1577 - val_accuracy: 0.8219 - val_loss: 0.8447\n",
      "Epoch 31/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9497 - loss: 0.1655 - val_accuracy: 0.8057 - val_loss: 0.7333\n",
      "Epoch 32/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9498 - loss: 0.1274 - val_accuracy: 0.8138 - val_loss: 0.8021\n",
      "Epoch 33/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9591 - loss: 0.1095 - val_accuracy: 0.8138 - val_loss: 0.8262\n",
      "Epoch 34/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9675 - loss: 0.0821 - val_accuracy: 0.8151 - val_loss: 0.9577\n",
      "Epoch 35/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9726 - loss: 0.0821 - val_accuracy: 0.8057 - val_loss: 0.9668\n",
      "Epoch 36/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9698 - loss: 0.0834 - val_accuracy: 0.8070 - val_loss: 0.9570\n",
      "Epoch 37/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9738 - loss: 0.0668 - val_accuracy: 0.8111 - val_loss: 0.9507\n",
      "Epoch 38/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9239 - loss: 0.4935 - val_accuracy: 0.8151 - val_loss: 0.5681\n",
      "Epoch 39/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8768 - loss: 0.3137 - val_accuracy: 0.8084 - val_loss: 0.8199\n",
      "Epoch 40/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9224 - loss: 0.1883 - val_accuracy: 0.8016 - val_loss: 0.8287\n",
      "Epoch 41/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9505 - loss: 0.1463 - val_accuracy: 0.8111 - val_loss: 1.0378\n",
      "Epoch 42/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9248 - loss: 0.2902 - val_accuracy: 0.7976 - val_loss: 0.9777\n",
      "Epoch 43/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9666 - loss: 0.1273 - val_accuracy: 0.7949 - val_loss: 1.0454\n",
      "Epoch 44/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9640 - loss: 0.1083 - val_accuracy: 0.7989 - val_loss: 1.0917\n",
      "Epoch 45/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9704 - loss: 0.0927 - val_accuracy: 0.7908 - val_loss: 1.1211\n",
      "Epoch 46/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9718 - loss: 0.0845 - val_accuracy: 0.7908 - val_loss: 1.1778\n",
      "Epoch 47/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9706 - loss: 0.1553 - val_accuracy: 0.7935 - val_loss: 1.0140\n",
      "Epoch 48/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9833 - loss: 0.0612 - val_accuracy: 0.7989 - val_loss: 1.2942\n",
      "Epoch 49/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9787 - loss: 0.0614 - val_accuracy: 0.8084 - val_loss: 1.3882\n",
      "Epoch 50/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9779 - loss: 0.0575 - val_accuracy: 0.8070 - val_loss: 1.5736\n",
      "Epoch 51/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9778 - loss: 0.0588 - val_accuracy: 0.7949 - val_loss: 1.2890\n",
      "Epoch 52/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9822 - loss: 0.0599 - val_accuracy: 0.7895 - val_loss: 1.3676\n",
      "Epoch 53/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9876 - loss: 0.0514 - val_accuracy: 0.8003 - val_loss: 1.4454\n",
      "Epoch 54/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9853 - loss: 0.0409 - val_accuracy: 0.8016 - val_loss: 1.8886\n",
      "Epoch 55/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9922 - loss: 0.0336 - val_accuracy: 0.8057 - val_loss: 1.6002\n",
      "Epoch 56/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9905 - loss: 0.0297 - val_accuracy: 0.7976 - val_loss: 1.4528\n",
      "Epoch 57/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9863 - loss: 0.0309 - val_accuracy: 0.8084 - val_loss: 1.7367\n",
      "Epoch 58/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9844 - loss: 0.0346 - val_accuracy: 0.7949 - val_loss: 1.6896\n",
      "Epoch 59/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9874 - loss: 0.0298 - val_accuracy: 0.8070 - val_loss: 1.8260\n",
      "Epoch 60/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9923 - loss: 0.0253 - val_accuracy: 0.8070 - val_loss: 1.5885\n",
      "Epoch 61/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9847 - loss: 0.0836 - val_accuracy: 0.8016 - val_loss: 1.8147\n",
      "Epoch 62/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9906 - loss: 0.0352 - val_accuracy: 0.8097 - val_loss: 2.2056\n",
      "Epoch 63/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9909 - loss: 0.0234 - val_accuracy: 0.8043 - val_loss: 1.7398\n",
      "Epoch 64/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9921 - loss: 0.0204 - val_accuracy: 0.7935 - val_loss: 1.9425\n",
      "Epoch 65/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9935 - loss: 0.0249 - val_accuracy: 0.7895 - val_loss: 2.0584\n",
      "Epoch 66/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9841 - loss: 0.0383 - val_accuracy: 0.8016 - val_loss: 1.7797\n",
      "Epoch 67/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9873 - loss: 0.0342 - val_accuracy: 0.7962 - val_loss: 2.0276\n",
      "Epoch 68/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9903 - loss: 0.0518 - val_accuracy: 0.7922 - val_loss: 1.4834\n",
      "Epoch 69/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9918 - loss: 0.0303 - val_accuracy: 0.7827 - val_loss: 1.4197\n",
      "Epoch 70/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9930 - loss: 0.0285 - val_accuracy: 0.7908 - val_loss: 1.8459\n",
      "Epoch 71/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9935 - loss: 0.0232 - val_accuracy: 0.8016 - val_loss: 1.4436\n",
      "Epoch 72/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9865 - loss: 0.0595 - val_accuracy: 0.8030 - val_loss: 1.7376\n",
      "Epoch 73/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9916 - loss: 0.0340 - val_accuracy: 0.8124 - val_loss: 1.7515\n",
      "Epoch 74/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.0295 - val_accuracy: 0.8097 - val_loss: 1.8736\n",
      "Epoch 75/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9896 - loss: 0.0213 - val_accuracy: 0.7935 - val_loss: 1.8032\n",
      "Epoch 76/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9939 - loss: 0.0174 - val_accuracy: 0.8016 - val_loss: 1.8542\n",
      "Epoch 77/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9917 - loss: 0.0251 - val_accuracy: 0.8003 - val_loss: 1.7473\n",
      "Epoch 78/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9925 - loss: 0.0350 - val_accuracy: 0.8070 - val_loss: 2.0413\n",
      "Epoch 79/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9850 - loss: 0.0619 - val_accuracy: 0.7814 - val_loss: 1.6124\n",
      "Epoch 80/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9936 - loss: 0.0249 - val_accuracy: 0.7908 - val_loss: 1.5050\n",
      "Epoch 81/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9910 - loss: 0.0272 - val_accuracy: 0.7989 - val_loss: 1.7712\n",
      "Epoch 82/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9909 - loss: 0.0270 - val_accuracy: 0.7868 - val_loss: 1.6791\n",
      "Epoch 83/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9945 - loss: 0.0165 - val_accuracy: 0.7895 - val_loss: 1.8391\n",
      "Epoch 84/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9895 - loss: 0.0331 - val_accuracy: 0.8043 - val_loss: 2.4720\n",
      "Epoch 85/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9886 - loss: 0.0274 - val_accuracy: 0.8030 - val_loss: 1.9877\n",
      "Epoch 86/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9895 - loss: 0.0287 - val_accuracy: 0.7976 - val_loss: 2.5787\n",
      "Epoch 87/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9897 - loss: 0.0408 - val_accuracy: 0.8016 - val_loss: 2.2134\n",
      "Epoch 88/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9875 - loss: 0.0303 - val_accuracy: 0.7868 - val_loss: 2.2712\n",
      "Epoch 89/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9934 - loss: 0.0173 - val_accuracy: 0.8057 - val_loss: 2.7456\n",
      "Epoch 90/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9799 - loss: 0.0604 - val_accuracy: 0.8016 - val_loss: 2.1627\n",
      "Epoch 91/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9808 - loss: 0.0942 - val_accuracy: 0.8124 - val_loss: 1.5975\n",
      "Epoch 92/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9907 - loss: 0.0261 - val_accuracy: 0.8124 - val_loss: 1.8239\n",
      "Epoch 93/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9925 - loss: 0.0297 - val_accuracy: 0.7949 - val_loss: 1.3913\n",
      "Epoch 94/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9949 - loss: 0.0216 - val_accuracy: 0.7733 - val_loss: 1.5648\n",
      "Epoch 95/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9870 - loss: 0.0332 - val_accuracy: 0.7881 - val_loss: 1.8404\n",
      "Epoch 96/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9898 - loss: 0.0242 - val_accuracy: 0.8043 - val_loss: 1.8915\n",
      "Epoch 97/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9926 - loss: 0.0185 - val_accuracy: 0.8070 - val_loss: 1.7662\n",
      "Epoch 98/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9915 - loss: 0.0189 - val_accuracy: 0.7935 - val_loss: 2.2608\n",
      "Epoch 99/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9879 - loss: 0.0653 - val_accuracy: 0.7895 - val_loss: 2.1278\n",
      "Epoch 100/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9882 - loss: 0.0320 - val_accuracy: 0.7773 - val_loss: 2.3076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7b80630d3210>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data, labels, epochs=100, batch_size=32, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c3463f02-b266-417d-b35c-b369e9c36352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3704, 2089, 1)\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[[9.9622744e-01]\n",
      " [1.9336412e-07]\n",
      " [1.0000000e+00]\n",
      " ...\n",
      " [9.9951065e-01]\n",
      " [8.2865191e-01]\n",
      " [9.9999917e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(np.expand_dims(data, axis=-1).shape)\n",
    "\n",
    "preds = model.predict(np.expand_dims(data, axis=-1))\n",
    "\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "91d7ca48-2b22-4ab6-b474-616f360ba28a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3704/3704 [00:00<00:00, 122831.29it/s]\n"
     ]
    }
   ],
   "source": [
    "class_list = {'0': 'A', '1': 'B'}\n",
    "\n",
    "num_high = 0\n",
    "num_mis_high = 0\n",
    "num_mis_low = 0\n",
    "\n",
    "tot_exc = 0\n",
    "\n",
    "for i, pred in enumerate(tqdm(preds)):\n",
    "    conf = np.abs(pred[0]-0.5)+0.5\n",
    "    pred_class = int(np.round(pred[0]))\n",
    "\n",
    "    #plt.scatter(np.arange(0, len(data[i][data[i] != 0]))*10, data[i][data[i] != 0])\n",
    "\n",
    "    #plt.xlabel('Time')\n",
    "    #plt.ylabel('Count')\n",
    "\n",
    "    #plt.title(f\"{ids[i]}, Pred. Class: {class_list[str(pred_class)]}, Actual Class: {class_list[str(labels[i])]}, Conf = {np.round(conf, 3)}\")\n",
    "\n",
    "    if peak_count[i] < 10:\n",
    "        #plt.close()\n",
    "        continue\n",
    "\n",
    "    tot_exc += 1\n",
    "    \n",
    "    if conf > 0.9:\n",
    "        #plt.savefig(f'classifications/high_confidence/{ids[i]}.png')\n",
    "        num_high += 1\n",
    "\n",
    "        if class_list[str(pred_class)] != class_list[str(labels[i])]:\n",
    "            num_mis_high += 1\n",
    "            #plt.show()\n",
    "    else:\n",
    "        #plt.savefig(f'classifications/low_confidence/{ids[i]}.png')\n",
    "\n",
    "        if class_list[str(pred_class)] != class_list[str(labels[i])]:\n",
    "            num_mis_low += 1\n",
    "            #plt.show()\n",
    "\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "581d0e90-8108-4714-8ae3-9dc3a6ac9af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of high confidence classifications = 3637\n",
      "Number of low confidence classifications = 67\n",
      "Percentage of high confidence = 0.9819114470842333\n",
      "Total misclassified = 160\n",
      "Accuracy in total = 0.9568034557235421\n",
      "Accuracy of high confidence = 0.963706351388507\n",
      "Accuracy of low confidence = 0.582089552238806\n"
     ]
    }
   ],
   "source": [
    "# cutoff = 0.8\n",
    "\n",
    "print(f'Number of high confidence classifications = {num_high}')\n",
    "print(f'Number of low confidence classifications = {len(preds) - num_high}')\n",
    "print(f'Percentage of high confidence = {num_high/len(preds)}')\n",
    "\n",
    "print(f'Total misclassified = {num_mis_high + num_mis_low}')\n",
    "print(f'Accuracy in total = {1-(num_mis_high + num_mis_low)/len(preds)}')\n",
    "\n",
    "print(f'Accuracy of high confidence = {1-num_mis_high/num_high}')\n",
    "print(f'Accuracy of low confidence = {1-num_mis_low/(len(preds) - num_high)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d02a8ac1-c9fb-48f6-bc71-bbca6d3d775b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot = 3159\n",
      "Number of high confidence classifications = 3071\n",
      "Number of low confidence classifications = 88\n",
      "Percentage of high confidence = 0.9721430832541944\n",
      "Total misclassified = 85\n",
      "Accuracy in total = 0.9730927508705286\n",
      "Accuracy of high confidence = 0.982090524259199\n",
      "Accuracy of low confidence = 0.6590909090909092\n"
     ]
    }
   ],
   "source": [
    "# cutoff = 0.9\n",
    "\n",
    "print(f'tot = {tot_exc}')\n",
    "\n",
    "print(f'Number of high confidence classifications = {num_high}')\n",
    "print(f'Number of low confidence classifications = {tot_exc - num_high}')\n",
    "print(f'Percentage of high confidence = {num_high/tot_exc}')\n",
    "\n",
    "print(f'Total misclassified = {num_mis_high + num_mis_low}')\n",
    "print(f'Accuracy in total = {1-(num_mis_high + num_mis_low)/tot_exc}')\n",
    "\n",
    "print(f'Accuracy of high confidence = {1-num_mis_high/num_high}')\n",
    "print(f'Accuracy of low confidence = {1-num_mis_low/(tot_exc - num_high)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
